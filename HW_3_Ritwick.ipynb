{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "yAowhPD0eNwK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "#input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "prompts = [ \"With a heavy heart,\",\n",
        "    \"Standing on the edge,\",\n",
        "    \"Surrounded by strangers,\",\n",
        "    \"Caught in a dilemma,\",\n",
        "    \"At the crossroads,\"]\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1UTtzUoebx5",
        "outputId": "b6a60691-b7b5-4330-844d-2d5e36573fb4"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.random.manual_seed(42)\n",
        "#Top- K sampling\n",
        "generation_params = {\n",
        "    #\"greedy_search\": {\"do_sample\": False, \"max_length\": 50},\n",
        "    #\"beam_search\": {\"num_beams\": 5, \"max_length\": 50, \"early_stopping\": True},\n",
        "    #\"top_k_sampling\": {\"do_sample\": True, \"top_k\": 50, \"max_length\": 50},\n",
        "    \"top_p_sampling\": {\"do_sample\": True, \"top_p\": 0.6, \"max_length\": 30, \"min_length\": 0 }\n",
        "}"
      ],
      "metadata": {
        "id": "kLpUuRQlepzT"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perplexity(input_text):\n",
        "    encodings = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    max_length = model.config.n_positions\n",
        "    input_ids = encodings.input_ids\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:, :-1] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        neg_log_likelihood = outputs.loss\n",
        "\n",
        "    return torch.exp(neg_log_likelihood).item()"
      ],
      "metadata": {
        "id": "TlSGR8miTpV5"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexities = {}\n",
        "for prompt in prompts:\n",
        "  for strategy_name, params in generation_params.items():\n",
        "      input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "      generated_outputs = model.generate(input_ids, **params, pad_token_id=tokenizer.eos_token_id)\n",
        "      generated_text = tokenizer.decode(generated_outputs[0], skip_special_tokens=True)\n",
        "      perplexity = calculate_perplexity(generated_text)\n",
        "      perplexities[strategy_name] = perplexity\n",
        "      print(f\"Strategy: {strategy_name}\\nGenerated Text: {generated_text}\\nPerplexity: {perplexity}\\n\")"
      ],
      "metadata": {
        "id": "m1KGBSuCg0Ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac45c9e3-785a-405c-a573-3fdd51358924"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strategy: top_p_sampling\n",
            "Generated Text: With a heavy heart, we are working hard to bring the game to a new level. We're excited to bring you the new version of the game\n",
            "Perplexity: 2.0831212997436523\n",
            "\n",
            "Strategy: top_p_sampling\n",
            "Generated Text: Standing on the edge, I could hear the heavy thud of the wind, and my heart was pounding.\n",
            "\n",
            "\"What is it?\" I\n",
            "Perplexity: 3.0335171222686768\n",
            "\n",
            "Strategy: top_p_sampling\n",
            "Generated Text: Surrounded by strangers, I had to try to get out of the house, and I had to do it on my own. But I've been\n",
            "Perplexity: 6.555111408233643\n",
            "\n",
            "Strategy: top_p_sampling\n",
            "Generated Text: Caught in a dilemma, the US has been in the business of making it harder for foreign governments to get a grip on the country.\n",
            "\n",
            "\n",
            "Perplexity: 160.3777313232422\n",
            "\n",
            "Strategy: top_p_sampling\n",
            "Generated Text: At the crossroads, a couple of things happened. One was that a few years ago, I started to get a little worried that the whole thing\n",
            "Perplexity: 7.0261945724487305\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "cnn=load_dataset(\"cnn_dailymail\", '2.0.0')"
      ],
      "metadata": {
        "id": "K1eYuOf-MW2S"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "CXVtqqpXlTcS"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn['train']['article'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "AL9QpeRPR05X",
        "outputId": "995463dc-c15d-48b8-ce25-60a90dcb9796"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def preprocess_function(examples):\n",
        "    #return tokenizer(examples['article'], truncation=True)"
      ],
      "metadata": {
        "id": "ef-sNVXTRk5h"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenized_cnn = cnn.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "W-ybpvm9RvFw"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#article_input_ids = tokenized_cnn['test']['input_ids'][0]"
      ],
      "metadata": {
        "id": "FDoquTIhcvgz"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_tensors = [torch.tensor([ids]) for ids in article_input_ids]"
      ],
      "metadata": {
        "id": "Sv5g868WcyZB"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outputs = []\n",
        "#for input_tensor in input_tensors:\n",
        "#    output = model.generate(input_tensor, **params, pad_token_id=tokenizer.eos_token_id)\n",
        " #   tokenizer.batch_decode(output, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "WsWQKUNbcyfj"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "te-o4MhnfE8T"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output = model.generate(article_input_ids, **params, pad_token_id=tokenizer.eos_token_id)\n",
        "#tokenizer.batch_decode(output, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "9tb6U8eOe0m6"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counter to track generated summaries\n",
        "#summary_count = 0\n",
        "\n",
        "#for article in cnn['test']['article']:\n",
        "  # Break the loop if 50 summaries are generated\n",
        " # if summary_count >= 50:\n",
        " #   break\n",
        "\n",
        " # tokenized_article = tokenizer(article, truncation=True)\n",
        " # input_ids = torch.tensor(tokenized_article['input_ids'])\n",
        " # output = model.generate(input_ids, **params, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  # Process the generated summary (e.g., print or store)\n",
        "  #print(f\"Summary {summary_count + 1}:\", output[0]['generated_text'])  # Accessing generated text from the first output element\n",
        "\n",
        " # summary_count += 1\n"
      ],
      "metadata": {
        "id": "FKArRc6ZnHrm"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn['test']['article'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "nB6w51BhnQnj",
        "outputId": "218d0fa5-4cec-4512-8fbe-5c3c600a7964"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame()"
      ],
      "metadata": {
        "id": "z_tfq6NdG-Um"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install evaluate, rouge_score, bert_score"
      ],
      "metadata": {
        "id": "4l1ydTXAJT5m"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "rouge_score=evaluate.load('rouge')\n",
        "bert_score=evaluate.load('bertscore')"
      ],
      "metadata": {
        "id": "marZRYXXJLy8"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "for i in range(50):\n",
        "    a = cnn['test']['article'][i]\n",
        "    r=cnn[f'test']['highlights'][i]\n",
        "    b = tokenizer(a, truncation=True, return_tensors=\"pt\", max_length=1024).input_ids\n",
        "    o = model.generate(b, **params, pad_token_id=tokenizer.eos_token_id)\n",
        "    gt = tokenizer.decode(o[0], skip_special_tokens=True)\n",
        "\n",
        "    rouge_score_value = rouge_score.compute(predictions=[gt], references=[cnn['test']['highlights'][i]])\n",
        "    bert_score_value = bert_score.compute(predictions=[gt], references=[cnn['test']['highlights'][i]], lang=\"en\")\n",
        "\n",
        "    # Create a new DataFrame or append to an existing one\n",
        "    if i == 0:\n",
        "        df = pd.DataFrame({'Input Text': [a], 'Generated Text': [gt], 'Rouge Score': [rouge_score_value], 'BERT Score': [bert_score_value]})\n",
        "    else:\n",
        "        new_row = pd.DataFrame({'Input Text': [a], 'Generated Text': [gt], 'Rouge Score': [rouge_score_value], 'BERT Score': [bert_score_value]}, index=[i])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "    print(f\"Generated text {i}: {gt}\\n Rouge: {rouge_score_value} \\n Bert_Score: {bert_score_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrTSSR66Moco",
        "outputId": "96e3e2c8-af96-44af-ccb4-21521d1e720f"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text 0: The Palestinian Authority becomes the 123rd member of the International Criminal Court. The move gives the court jurisdiction over alleged crimes in Palestinian territories.\n",
            " Rouge: {'rouge1': 0.44827586206896547, 'rouge2': 0.25, 'rougeL': 0.31034482758620696, 'rougeLsum': 0.44827586206896547} \n",
            " Bert_Score: {'precision': [0.9076894521713257], 'recall': [0.8876417279243469], 'f1': [0.8975536227226257], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 1: A dog apparently hit by a car and buried in a field survives. The dog, now named Theia, was found emaciated\n",
            " Rouge: {'rouge1': 0.4375, 'rouge2': 0.25806451612903225, 'rougeL': 0.40625, 'rougeLsum': 0.40625} \n",
            " Bert_Score: {'precision': [0.9049350619316101], 'recall': [0.8699348568916321], 'f1': [0.8870898485183716], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 2: Mohammad Javad Zarif is the Iranian foreign minister. He has been John Kerry's opposite number in securing a breakthrough in nuclear discussions\n",
            " Rouge: {'rouge1': 0.48275862068965525, 'rouge2': 0.25, 'rougeL': 0.3103448275862069, 'rougeLsum': 0.48275862068965525} \n",
            " Bert_Score: {'precision': [0.9066729545593262], 'recall': [0.879257321357727], 'f1': [0.8927547335624695], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 3: The five were exposed to Ebola in Sierra Leone in March. None of them developed the deadly virus.\n",
            " Rouge: {'rouge1': 0.4333333333333334, 'rouge2': 0.20689655172413793, 'rougeL': 0.36666666666666675, 'rougeLsum': 0.4} \n",
            " Bert_Score: {'precision': [0.9297922849655151], 'recall': [0.8665285110473633], 'f1': [0.8970463871955872], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 4: The student is no longer on campus and will face student conduct review. Officials are still trying to determine if other people were involved. The\n",
            " Rouge: {'rouge1': 0.44776119402985076, 'rouge2': 0.24615384615384614, 'rougeL': 0.3880597014925373, 'rougeLsum': 0.41791044776119407} \n",
            " Bert_Score: {'precision': [0.9154406189918518], 'recall': [0.8750228881835938], 'f1': [0.8947755694389343], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 5: Trey Moses asked Ellie Meredith to be his prom date. He made the prom-posal in the gym during Ellie's P.E\n",
            " Rouge: {'rouge1': 0.2978723404255319, 'rouge2': 0.08888888888888888, 'rougeL': 0.2127659574468085, 'rougeLsum': 0.2127659574468085} \n",
            " Bert_Score: {'precision': [0.8761938214302063], 'recall': [0.8565270304679871], 'f1': [0.8662487864494324], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 6: Amnesty International says governments are using the threat of terrorism to advance executions. At least 607 people were executed around the world in 2014\n",
            " Rouge: {'rouge1': 0.3846153846153846, 'rouge2': 0.26315789473684215, 'rougeL': 0.30769230769230765, 'rougeLsum': 0.30769230769230765} \n",
            " Bert_Score: {'precision': [0.9104962348937988], 'recall': [0.862553596496582], 'f1': [0.8858767747879028], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 7: Andrew Getty appears to have died of natural causes, police say. The 47-year-old had \"several health issues,\" police\n",
            " Rouge: {'rouge1': 0.3125, 'rouge2': 0.16129032258064516, 'rougeL': 0.3125, 'rougeLsum': 0.3125} \n",
            " Bert_Score: {'precision': [0.9128607511520386], 'recall': [0.8799081444740295], 'f1': [0.8960815668106079], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 8: Maysak gained super typhoon status just a few days ago. It's now a tropical storm, but its winds are\n",
            " Rouge: {'rouge1': 0.4347826086956522, 'rouge2': 0.1818181818181818, 'rougeL': 0.3043478260869565, 'rougeLsum': 0.34782608695652173} \n",
            " Bert_Score: {'precision': [0.8969843983650208], 'recall': [0.8710238337516785], 'f1': [0.8838135004043579], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 9: Bob Barker hosted the TV game show for 35 years before stepping down in 2007. Barker handled the first price-guessing game of the\n",
            " Rouge: {'rouge1': 0.32558139534883723, 'rouge2': 0.0975609756097561, 'rougeL': 0.23255813953488372, 'rougeLsum': 0.32558139534883723} \n",
            " Bert_Score: {'precision': [0.8756589293479919], 'recall': [0.8723561763763428], 'f1': [0.8740043640136719], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 10: Yahya Rashid, 19, was arrested at Luton airport on Tuesday. He's charged with engaging in conduct in preparation of\n",
            " Rouge: {'rouge1': 0.4150943396226416, 'rouge2': 0.23529411764705882, 'rougeL': 0.4150943396226416, 'rougeLsum': 0.4150943396226416} \n",
            " Bert_Score: {'precision': [0.869042158126831], 'recall': [0.8764337301254272], 'f1': [0.8727222681045532], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 11: Paul Walker died in a car crash in November 2013. The film \"Furious 7\" is released Friday.\n",
            " Rouge: {'rouge1': 0.38095238095238104, 'rouge2': 0.1, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333} \n",
            " Bert_Score: {'precision': [0.9060274362564087], 'recall': [0.867763876914978], 'f1': [0.8864829540252686], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 12: Anne Frank died of typhus in a Nazi concentration camp at the age of 15. Researchers re-examined archives of the Red\n",
            " Rouge: {'rouge1': 0.34615384615384615, 'rouge2': 0.19999999999999998, 'rougeL': 0.30769230769230765, 'rougeLsum': 0.34615384615384615} \n",
            " Bert_Score: {'precision': [0.8835710287094116], 'recall': [0.8553885817527771], 'f1': [0.8692514300346375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 13: Mike Pence signed a religious freedom law that opens the door to discrimination against gays and lesbians. Julian Zelizer: Pence has scored a lot\n",
            " Rouge: {'rouge1': 0.14705882352941177, 'rouge2': 0.0, 'rougeL': 0.08823529411764705, 'rougeLsum': 0.08823529411764705} \n",
            " Bert_Score: {'precision': [0.8598501682281494], 'recall': [0.834773600101471], 'f1': [0.8471263647079468], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 14: Mötley Crüe's Vince Neil reminded us of the dangers of tackling \"The Star-Spangled Banner\" The late\n",
            " Rouge: {'rouge1': 0.05555555555555556, 'rouge2': 0.0, 'rougeL': 0.05555555555555556, 'rougeLsum': 0.05555555555555556} \n",
            " Bert_Score: {'precision': [0.8106385469436646], 'recall': [0.8401138186454773], 'f1': [0.82511305809021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 15: Walmart is emerging as a bellwether for shifting public opinion on hot-button political issues. Former Minnesota Gov. Tim Pawl\n",
            " Rouge: {'rouge1': 0.12307692307692307, 'rouge2': 0.0, 'rougeL': 0.061538461538461535, 'rougeLsum': 0.12307692307692307} \n",
            " Bert_Score: {'precision': [0.8375508785247803], 'recall': [0.8157959580421448], 'f1': [0.8265303373336792], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 16: Amnesty International releases its annual review of the death penalty worldwide. Amnesty International: Governments using death penalty in misguided attempt to tackle crime.\n",
            " Rouge: {'rouge1': 0.4137931034482759, 'rouge2': 0.35714285714285715, 'rougeL': 0.4137931034482759, 'rougeLsum': 0.4137931034482759} \n",
            " Bert_Score: {'precision': [0.9362978935241699], 'recall': [0.8775231838226318], 'f1': [0.9059582352638245], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 17: French prosecutor says he's not aware of any video footage from on board the plane. Two magazines claim to have found a cell phone video\n",
            " Rouge: {'rouge1': 0.13333333333333333, 'rouge2': 0.0273972602739726, 'rougeL': 0.10666666666666666, 'rougeLsum': 0.13333333333333333} \n",
            " Bert_Score: {'precision': [0.8782288432121277], 'recall': [0.8289468288421631], 'f1': [0.8528764247894287], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 18: The Rev. Robert H. Schuller was diagnosed with esophageal cancer in August 2013. He was also the founder of\n",
            " Rouge: {'rouge1': 0.5652173913043478, 'rouge2': 0.27272727272727276, 'rougeL': 0.5217391304347826, 'rougeLsum': 0.5217391304347826} \n",
            " Bert_Score: {'precision': [0.9429805874824524], 'recall': [0.8938652873039246], 'f1': [0.917766273021698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 19: Michele Bachmann compares President Obama to the co-pilot of the doomed Germanwings flight. Bachmann is no stranger to\n",
            " Rouge: {'rouge1': 0.23076923076923078, 'rouge2': 0.12000000000000002, 'rougeL': 0.19230769230769232, 'rougeLsum': 0.23076923076923078} \n",
            " Bert_Score: {'precision': [0.8656915426254272], 'recall': [0.8361790776252747], 'f1': [0.8506793975830078], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 20: Louis Jordan, 37, was found by a container ship hundreds of miles from land. He had been at sea for more than two months\n",
            " Rouge: {'rouge1': 0.16666666666666669, 'rouge2': 0.06896551724137931, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669} \n",
            " Bert_Score: {'precision': [0.8641538619995117], 'recall': [0.8401859998703003], 'f1': [0.8520013689994812], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 21: U.S. and its negotiating partners reached a very strong framework agreement with Iran. Peter Bergen: The debate that has already begun\n",
            " Rouge: {'rouge1': 0.21874999999999997, 'rouge2': 0.03225806451612904, 'rougeL': 0.09374999999999999, 'rougeLsum': 0.09374999999999999} \n",
            " Bert_Score: {'precision': [0.8767364621162415], 'recall': [0.8328462839126587], 'f1': [0.8542279601097107], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 22: California is a breadbasket to the nation, growing more than a third of its vegetables. The drought is affecting other states, too\n",
            " Rouge: {'rouge1': 0.34375000000000006, 'rouge2': 0.03225806451612904, 'rougeL': 0.15624999999999997, 'rougeLsum': 0.28125} \n",
            " Bert_Score: {'precision': [0.8489724397659302], 'recall': [0.8363100290298462], 'f1': [0.8425936698913574], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 23: Keonna Thomas, 30, is charged with trying to travel overseas to fight for ISIS. She's one of three women arrested this week\n",
            " Rouge: {'rouge1': 0.631578947368421, 'rouge2': 0.4, 'rougeL': 0.5263157894736842, 'rougeLsum': 0.5614035087719297} \n",
            " Bert_Score: {'precision': [0.95368492603302], 'recall': [0.9062978029251099], 'f1': [0.9293876886367798], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 24: Iranian sports official says women will be allowed to attend some sports events. The ban has been in place since the Islamic Revolution in 1979\n",
            " Rouge: {'rouge1': 0.5384615384615384, 'rouge2': 0.2, 'rougeL': 0.3846153846153846, 'rougeLsum': 0.4230769230769231} \n",
            " Bert_Score: {'precision': [0.9100302457809448], 'recall': [0.8918566703796387], 'f1': [0.9008517861366272], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 25: Amos Yee was arrested and held pending bail in Singapore for his anti-Lee Kuan Yew harangue. Yee\n",
            " Rouge: {'rouge1': 0.031746031746031744, 'rouge2': 0.0, 'rougeL': 0.031746031746031744, 'rougeLsum': 0.031746031746031744} \n",
            " Bert_Score: {'precision': [0.8100077509880066], 'recall': [0.820988655090332], 'f1': [0.8154612183570862], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 26: Avril Lavigne says she was bedridden for five months after contracting Lyme disease. \"I felt like I couldn't breathe, I\n",
            " Rouge: {'rouge1': 0.3111111111111111, 'rouge2': 0.18604651162790697, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.3111111111111111} \n",
            " Bert_Score: {'precision': [0.8746227622032166], 'recall': [0.8702769875526428], 'f1': [0.8724444508552551], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 27: Former heavyweight champ Mike Tyson lived in a gaudy, abandoned mansion in Ohio. CNN's Karl Penhaul spoke to a shepherd who\n",
            " Rouge: {'rouge1': 0.3255813953488372, 'rouge2': 0.14634146341463414, 'rougeL': 0.18604651162790697, 'rougeLsum': 0.2790697674418604} \n",
            " Bert_Score: {'precision': [0.8575219511985779], 'recall': [0.8548563122749329], 'f1': [0.8561870455741882], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 28: Israeli Prime Minister Benjamin Netanyahu says he sees better options than \"this bad deal or war\" His comments come as Democrats and Republicans spar over\n",
            " Rouge: {'rouge1': 0.20833333333333331, 'rouge2': 0.043478260869565216, 'rougeL': 0.20833333333333331, 'rougeLsum': 0.20833333333333331} \n",
            " Bert_Score: {'precision': [0.8617395162582397], 'recall': [0.8751577138900757], 'f1': [0.8683967590332031], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 29: Memories Pizza in Indiana refused to cater a same-sex couple's wedding. Critics said the new law would allow businesses to discriminate against\n",
            " Rouge: {'rouge1': 0.4489795918367347, 'rouge2': 0.3404255319148936, 'rougeL': 0.4081632653061225, 'rougeLsum': 0.3673469387755102} \n",
            " Bert_Score: {'precision': [0.8956377506256104], 'recall': [0.8825281858444214], 'f1': [0.889034628868103], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 30: Police in the Indian city of Malegaon, in the western state of Maharashtra, are requiring identity cards for an unusual group of residents\n",
            " Rouge: {'rouge1': 0.30379746835443033, 'rouge2': 0.12987012987012989, 'rougeL': 0.22784810126582278, 'rougeLsum': 0.27848101265822783} \n",
            " Bert_Score: {'precision': [0.9106804132461548], 'recall': [0.8576759099960327], 'f1': [0.8833837509155273], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 31: It's hard to swallow the idea of a single person being stranded at sea for days, weeks, if not months. Miracles do\n",
            " Rouge: {'rouge1': 0.18181818181818182, 'rouge2': 0.03125, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.12121212121212122} \n",
            " Bert_Score: {'precision': [0.8613158464431763], 'recall': [0.8403622508049011], 'f1': [0.8507100939750671], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 32: The Large Hadron Collider (LHC) is the largest particle accelerator in the world. The purpose of the project is to recreate the\n",
            " Rouge: {'rouge1': 0.35000000000000003, 'rouge2': 0.21052631578947367, 'rougeL': 0.35000000000000003, 'rougeLsum': 0.35000000000000003} \n",
            " Bert_Score: {'precision': [0.89287269115448], 'recall': [0.8870007395744324], 'f1': [0.8899270296096802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 33: Kevone Charleston, 36, is suspected of 32 commercial robberies dating to November 2013. FBI agents and task force officers were following him\n",
            " Rouge: {'rouge1': 0.20833333333333331, 'rouge2': 0.08695652173913043, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.12499999999999997} \n",
            " Bert_Score: {'precision': [0.8380582332611084], 'recall': [0.8562437295913696], 'f1': [0.8470534086227417], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 34: The total lunar eclipse will only last four minutes and 43 seconds. It started at 3:16 a.m. Pacific Daylight Time\n",
            " Rouge: {'rouge1': 0.3508771929824561, 'rouge2': 0.2545454545454545, 'rougeL': 0.3508771929824561, 'rougeLsum': 0.3508771929824561} \n",
            " Bert_Score: {'precision': [0.8978192806243896], 'recall': [0.8641843795776367], 'f1': [0.8806807994842529], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 35: Al-Shabaab has claimed an attack on Garissa University College in eastern Kenya. The attack is another step in the ongoing escalation\n",
            " Rouge: {'rouge1': 0.27272727272727276, 'rouge2': 0.09374999999999999, 'rougeL': 0.24242424242424246, 'rougeLsum': 0.24242424242424246} \n",
            " Bert_Score: {'precision': [0.8981965780258179], 'recall': [0.8614614605903625], 'f1': [0.8794455528259277], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 36: Easter is a cornerstone event in the Christian faith, but it's surrounded by interesting quirks. Unlike Christmas, it doesn't fall on\n",
            " Rouge: {'rouge1': 0.3508771929824562, 'rouge2': 0.2545454545454546, 'rougeL': 0.3508771929824562, 'rougeLsum': 0.3508771929824562} \n",
            " Bert_Score: {'precision': [0.9008277654647827], 'recall': [0.8775949478149414], 'f1': [0.8890596032142639], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 37: The NCAA says it has no legal responsibility to ensure the academic integrity of the courses offered to student-athletes. The NCAA\n",
            " Rouge: {'rouge1': 0.2903225806451613, 'rouge2': 0.1, 'rougeL': 0.19354838709677416, 'rougeLsum': 0.22580645161290322} \n",
            " Bert_Score: {'precision': [0.9144048690795898], 'recall': [0.8705742359161377], 'f1': [0.8919514417648315], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 38: A Connecticut teen who has been forced to have chemotherapy will remain in temporary custody. The 17-year-old is in remission after nearly\n",
            " Rouge: {'rouge1': 0.2333333333333333, 'rouge2': 0.034482758620689655, 'rougeL': 0.2, 'rougeLsum': 0.2} \n",
            " Bert_Score: {'precision': [0.8819496035575867], 'recall': [0.8579172492027283], 'f1': [0.869767427444458], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 39: \"Uptown Funk!\" is the longest-leading Billboard Hot 100 of the 2010s. It's also just the 10th single\n",
            " Rouge: {'rouge1': 0.17777777777777778, 'rouge2': 0.0, 'rougeL': 0.17777777777777778, 'rougeLsum': 0.17777777777777778} \n",
            " Bert_Score: {'precision': [0.8368082046508789], 'recall': [0.8221282958984375], 'f1': [0.8294033408164978], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 40: The temperature was recorded at Argentina's Esperanza Base on the northern tip of the Antarctica Peninsula. The World Meteorological Organization is in the\n",
            " Rouge: {'rouge1': 0.6222222222222222, 'rouge2': 0.5116279069767442, 'rougeL': 0.6222222222222222, 'rougeLsum': 0.6222222222222222} \n",
            " Bert_Score: {'precision': [0.9008231163024902], 'recall': [0.9198877811431885], 'f1': [0.9102556705474854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 41: The U.S. Religious Freedom Restoration Act became law in 1993. 20 states have some version of the law, but claims under those\n",
            " Rouge: {'rouge1': 0.0821917808219178, 'rouge2': 0.0, 'rougeL': 0.0547945205479452, 'rougeLsum': 0.0821917808219178} \n",
            " Bert_Score: {'precision': [0.8256585597991943], 'recall': [0.8012470006942749], 'f1': [0.8132696151733398], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 42: Robert Lewis Burns Jr. was part of the genre-defining band's original lineup. He died after his car hit a mailbox and\n",
            " Rouge: {'rouge1': 0.6956521739130435, 'rouge2': 0.5909090909090909, 'rougeL': 0.6956521739130435, 'rougeLsum': 0.6956521739130435} \n",
            " Bert_Score: {'precision': [0.9355967044830322], 'recall': [0.901288628578186], 'f1': [0.9181222319602966], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 43: Kim Ki-Jong is accused of stabbing U.S. Ambassador Mark Lippert in Seoul. He is also charged with assaulting\n",
            " Rouge: {'rouge1': 0.5666666666666667, 'rouge2': 0.41379310344827586, 'rougeL': 0.43333333333333335, 'rougeLsum': 0.5333333333333333} \n",
            " Bert_Score: {'precision': [0.954025387763977], 'recall': [0.8949292302131653], 'f1': [0.9235329031944275], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 44: Rurik Jutting, 29, is charged with two counts of murder in Hong Kong. Police found the bodies of two women\n",
            " Rouge: {'rouge1': 0.46511627906976744, 'rouge2': 0.0975609756097561, 'rougeL': 0.23255813953488372, 'rougeLsum': 0.3255813953488372} \n",
            " Bert_Score: {'precision': [0.9141544103622437], 'recall': [0.8813778162002563], 'f1': [0.8974669575691223], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 45: Thai Smile unveils colorful new livery featuring Jake, Finn and Princess Bubblegum. The interior of the plane also has an\n",
            " Rouge: {'rouge1': 0.13043478260869565, 'rouge2': 0.04545454545454545, 'rougeL': 0.13043478260869565, 'rougeLsum': 0.13043478260869565} \n",
            " Bert_Score: {'precision': [0.8640385270118713], 'recall': [0.8323293328285217], 'f1': [0.8478875756263733], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 46: Manning is serving a 35-year prison sentence for leaking thousands of classified documents. She said she will be using a voice phone to\n",
            " Rouge: {'rouge1': 0.8799999999999999, 'rouge2': 0.7916666666666667, 'rougeL': 0.8799999999999999, 'rougeLsum': 0.8799999999999999} \n",
            " Bert_Score: {'precision': [0.9751830101013184], 'recall': [0.9518852233886719], 'f1': [0.9633932709693909], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 47: Reaching a good, solid agreement with Iran is a worthy, desirable goal. But the process has unfolded under the destructive influence of political\n",
            " Rouge: {'rouge1': 0.22641509433962265, 'rouge2': 0.0, 'rougeL': 0.15094339622641512, 'rougeLsum': 0.18867924528301885} \n",
            " Bert_Score: {'precision': [0.8679631948471069], 'recall': [0.8390675187110901], 'f1': [0.8532707691192627], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 48: \"Furious 7\" is getting the widest release in Universal's history. It has booked more than 10,500 screens in 63 territories\n",
            " Rouge: {'rouge1': 0.21818181818181817, 'rouge2': 0.07547169811320754, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182} \n",
            " Bert_Score: {'precision': [0.8702916502952576], 'recall': [0.8512316942214966], 'f1': [0.8606561422348022], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n",
            "Generated text 49: Deion Sanders Jr. tweeted that he only eats \"hood doughnuts\" His father reminded him he has a trust fund, a condo\n",
            " Rouge: {'rouge1': 0.37209302325581395, 'rouge2': 0.14634146341463414, 'rougeL': 0.3255813953488372, 'rougeLsum': 0.3255813953488372} \n",
            " Bert_Score: {'precision': [0.8899291753768921], 'recall': [0.8630045056343079], 'f1': [0.8762600421905518], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.38.2)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('Top-P Sampling.csv')"
      ],
      "metadata": {
        "id": "Ddm5CwqFS_R1"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('Top-P Sampling.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bT-c8-RfTyoL",
        "outputId": "5b05fc61-50c5-4c35-b607-a19a2d6bc0e7"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_634ceaa8-3075-4a16-8d09-51d40837f95a\", \"Top-P Sampling.csv\", 202711)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9a490YQna8H"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mfKp5DjXnpdV"
      },
      "execution_count": 194,
      "outputs": []
    }
  ]
}
